{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7429f8d",
   "metadata": {},
   "source": [
    "Let's generate some data to practice a t-test. You use a t-test when you want to determine if there is a significant difference between two data. Suppose you have pre-potion strength and post-potion strength, and there is no significant difference, then you cannot say that the learning (independent variable/manipulation) caused the score change, it may be due to error (paired samples t-test). You may also want to test reaction times of Minotaurs vs Centaurs, and there is a significant difference, you can say there is a meaningful difference due to species. \n",
    "\n",
    "Generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc4c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the normal distribution\n",
    "mean = 50  # Mean value\n",
    "std_dev = 15  # Standard deviation\n",
    "\n",
    "# Generate normally distributed data\n",
    "data = np.random.normal(mean, std_dev, 1000)\n",
    "\n",
    "#and a second one\n",
    "mean = 60\n",
    "std_dev=10\n",
    "data2 = np.random.normal(mean, std_dev, 1000)\n",
    "\n",
    "#and a third\n",
    "mean = 75\n",
    "std_dev=5\n",
    "data3 = np.random.normal(mean, std_dev, 1000)\n",
    "\n",
    "# Clip the data to fit within the [0, 100] range, this is an artifact from the test data but lets keep it for now.\n",
    "data = np.clip(data, 0, 100)\n",
    "data2 = np.clip(data2, 0, 100)\n",
    "data23 = np.clip(data3, 0, 100)\n",
    "\n",
    "# Now, 'data' contains 1000 data points that are normally distributed\n",
    "# but constrained within the [0, 100] range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e6280",
   "metadata": {},
   "source": [
    "t-test assumptions:\n",
    "\n",
    "1. The data are continuous.\n",
    "2. The sample data have been randomly sampled from a population.\n",
    "3. There is homogeneity of variance (homoscedasticity)(i.e., the variability of the data in each group is similar).\n",
    "4. The distribution is approximately normal (normally distributed, gaussian)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8a7ae",
   "metadata": {},
   "source": [
    "Let's assume 1 and 2 are true, and test 3 and 4. Starting with normality (4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32fc8e",
   "metadata": {},
   "source": [
    "GPT: \"What are the assumptions of Shapiro Wilkes tests\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf37db",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test is a statistical test used to assess the normality of a dataset. The test evaluates the null hypothesis that a given dataset follows a normal distribution. The assumptions of the Shapiro-Wilk test are as follows:\n",
    "\n",
    "Independence: The data points in the dataset should be independent of each other. This means that the value of one data point should not depend on or be influenced by the value of another data point.\n",
    "\n",
    "Random Sampling: The data should be obtained through random sampling, which ensures that the sample is representative of the population you are interested in.\n",
    "\n",
    "Continuous Data: The Shapiro-Wilk test is primarily designed for continuous data. It may not be appropriate for discrete data or data with a limited number of unique values.\n",
    "\n",
    "Unbiased and Identically Distributed (i.i.d.) Data: The data should be drawn from a population with the same distribution, and the distribution should be unbiased. In other words, the data should not be systematically biased in one direction.\n",
    "\n",
    "No Extreme Outliers: The presence of extreme outliers in the dataset can affect the test's performance. It's advisable to check for and potentially address outliers before conducting the test.\n",
    "\n",
    "Sufficient Sample Size: The test becomes more reliable with larger sample sizes. If the sample size is very small, the test's results may not be trustworthy.\n",
    "\n",
    "Normality as the Null Hypothesis: The Shapiro-Wilk test assumes that the null hypothesis is that the data is normally distributed. Therefore, it's used to test the data for deviation from a normal distribution.\n",
    "\n",
    "Keep in mind that no statistical test can definitively prove that data follows a normal distribution; these tests can only provide evidence for or against the null hypothesis of normality. It's also important to consider the practical significance of the results and whether deviations from normality, if present, are practically meaningful for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3a717",
   "metadata": {},
   "source": [
    "So we conduct the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1200276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appears to be normally distributed\n",
      "Data appears to be normally distributed\n",
      "Data appears to be normally distributed\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Perform the Shapiro-Wilk test on data 1\n",
    "statistic, p_value = stats.shapiro(data)\n",
    "\n",
    "# Check the p-value against a significance level (e.g., 0.05)\n",
    "if p_value > 0.05:\n",
    "    print(\"Data appears to be normally distributed\")\n",
    "else:\n",
    "    print(\"Data does not appear to be normally distributed\")\n",
    "    \n",
    "# Perform the Shapiro-Wilk test on data 2\n",
    "statistic, p_value = stats.shapiro(data2)\n",
    "\n",
    "# Check the p-value against a significance level (e.g., 0.05)\n",
    "if p_value > 0.05:\n",
    "    print(\"Data appears to be normally distributed\")\n",
    "else:\n",
    "    print(\"Data does not appear to be normally distributed\")\n",
    "    \n",
    "# Perform the Shapiro-Wilk test on data 3\n",
    "statistic, p_value = stats.shapiro(data3)\n",
    "\n",
    "# Check the p-value against a significance level (e.g., 0.05)\n",
    "if p_value > 0.05:\n",
    "    print(\"Data appears to be normally distributed\")\n",
    "else:\n",
    "    print(\"Data does not appear to be normally distributed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59a1d75",
   "metadata": {},
   "source": [
    "Then test homoscedasticity (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a893b37",
   "metadata": {},
   "source": [
    "GPT: \"Homooscedasticity test in python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bbe08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an array with 1 repeated 500 times and 0 repeated 500 times\n",
    "ones_array = np.ones(500)\n",
    "zeros_array = np.zeros(500)\n",
    "\n",
    "# Combine the two arrays and shuffle them randomly\n",
    "combined_array = np.concatenate((ones_array, zeros_array))\n",
    "np.random.shuffle(combined_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63d9b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homoscedasticity is not supported (p-value = 5.879107349791847e-212 )\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Assuming 'residuals' is a NumPy array or a list of residuals\n",
    "statistic, p_value = stats.levene(data3, combined_array)\n",
    "if p_value > 0.05:\n",
    "    print(\"Homoscedasticity is supported (p-value =\", p_value, \")\")\n",
    "else:\n",
    "    print(\"Homoscedasticity is not supported (p-value =\", p_value, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d8910",
   "metadata": {},
   "source": [
    "Unfortunately, we cannot use a normal t-test efficiently here because we did not meet and assumption of homoscedasticity. The alternative is to use a non-parametric test. For example, a Welche's t-test can be used for unequal variances.\n",
    "\n",
    "Welch's t-test: Also known as the unequal variances t-test, it is used when the variances of the two groups being compared are not assumed to be equal. It provides a more robust comparison when the variances differ between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb19787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -16.35888026055057\n",
      "P-value: 4.220542271424133e-56\n",
      "The difference between the groups is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(data, data2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Determine if the difference is statistically significant\n",
    "alpha = 0.05  # Set your significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The difference between the groups is statistically significant.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099660c",
   "metadata": {},
   "source": [
    "Neat, we have there is a significantly difference in this data. What other tests could we have used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294f7b2",
   "metadata": {},
   "source": [
    "GPT: \"List the types of t-tests\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e6f61",
   "metadata": {},
   "source": [
    "There are several types of t-tests used in statistics to compare means between two or more groups. The choice of which t-test to use depends on the specific characteristics of your data and the research question you are addressing. Here are some common types of t-tests:\n",
    "\n",
    "Independent Samples t-test: This test is used to compare the means of two independent groups to determine if there is a significant difference between them. It is often used when you have two different groups of subjects, and you want to assess whether a treatment or intervention had a significant effect.\n",
    "\n",
    "Paired Samples t-test (Dependent t-test): This test is used to compare the means of two related or paired groups. It is often used when the same subjects are measured before and after a treatment or intervention, and you want to determine if there is a significant difference between the paired measurements.\n",
    "\n",
    "One-Sample t-test: This test is used to compare the mean of a single sample to a known or hypothesized population mean to determine if there is a significant difference. It is often used when you have a sample and want to assess whether it represents a population with a specific mean.\n",
    "\n",
    "Welch's t-test: Also known as the unequal variances t-test, it is used when the variances of the two groups being compared are not assumed to be equal. It provides a more robust comparison when the variances differ between groups.\n",
    "\n",
    "The good news is, generally speaking, many statistical tests are robust to violating assumptions. Thus, you should also consider, can I still run an analysis with a violation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b1e030",
   "metadata": {},
   "source": [
    "GPT: \"Can you run a ttest if the data is not normal?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0588a27",
   "metadata": {},
   "source": [
    "Yes, you can run a t-test even if the data is not perfectly normal. T-tests are known for their robustness, meaning they can provide valid results even when the normality assumption is not met, as long as certain conditions are reasonably satisfied. The extent to which you can deviate from the normality assumption depends on factors such as the sample size, the shape of the data distribution, and the level of deviation.\n",
    "\n",
    "Here are some considerations:\n",
    "\n",
    "Sample Size: With larger sample sizes, t-tests tend to be more robust to deviations from normality. The Central Limit Theorem states that as the sample size increases, the distribution of sample means becomes approximately normal, even if the underlying data is not normally distributed. Therefore, t-tests are often valid with larger samples, even if the data is not perfectly normal.\n",
    "\n",
    "Symmetry and Skewness: T-tests can handle moderate levels of skewness, but very skewed or highly non-normal data might still impact the validity of the test.\n",
    "\n",
    "Outliers: Extreme outliers can affect the results of a t-test. You may want to check for and address outliers before conducting the test.\n",
    "\n",
    "Non-parametric Alternatives: If you have concerns about the normality of your data, or if your data is not reasonably close to a normal distribution, non-parametric tests like the Mann-Whitney U test (for independent samples) or the Wilcoxon signed-rank test (for paired samples) can be used as alternatives to t-tests.\n",
    "\n",
    "In summary, while t-tests assume normality, they can still be used when data is not perfectly normal, as long as you consider the factors mentioned above. However, for non-normal data, especially if you have small sample sizes and significant deviations from normality, it's often a good idea to explore non-parametric tests or other alternatives that are specifically designed for such situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41984abf",
   "metadata": {},
   "source": [
    "GPT: \"How to compute statistical power if an assumption is violated\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f857177",
   "metadata": {},
   "source": [
    "Computing statistical power when an assumption is violated can be challenging, as the extent and nature of the violation may affect the power calculations. In many cases, statistical power calculations are based on certain assumptions, and if these assumptions are severely violated, the power calculations may not accurately reflect the real-world scenario. However, you can still estimate statistical power with some caution by considering the following approaches:\n",
    "\n",
    "Simulations: One way to estimate power when assumptions are violated is through simulation studies. You can generate synthetic datasets that mimic the characteristics of your actual data, including the violations of assumptions. By simulating data, you can run your analysis many times with different simulated datasets and varying levels of violation. This can provide insights into the range of power values you might expect under different conditions.\n",
    "\n",
    "Non-parametric Tests: If the assumptions of parametric tests (e.g., t-tests or ANOVA) are violated, you can use non-parametric tests that don't rely on those assumptions. When using non-parametric tests, you can compute the power under the assumption that the data follow the specified non-parametric distribution (e.g., the Wilcoxon-Mann-Whitney test for independent samples or the Wilcoxon signed-rank test for paired samples).\n",
    "\n",
    "Robust Methods: Robust statistical methods are designed to handle violations of certain assumptions while still providing valid results. You can compute power under the assumption of robustness, taking into account the specific characteristics of the robust method you are using.\n",
    "\n",
    "Sample Size Determination: If you are planning a study and you anticipate that assumptions might be violated, you can perform a power analysis while taking those violations into account. You can estimate the required sample size needed to achieve a desired level of power, assuming certain levels of violation, and then plan your study accordingly.\n",
    "\n",
    "Monte Carlo Methods: Monte Carlo simulations involve repeatedly generating data under specific conditions and analyzing it using your chosen statistical method. This can help you estimate power under various scenarios, including those where assumptions are violated.\n",
    "\n",
    "It's important to recognize that power calculations become less reliable and more challenging when assumptions are violated. The power you calculate may serve as a rough estimate, but it may not precisely reflect the power of your specific analysis under real-world conditions. Therefore, it's essential to interpret the results with caution and consider sensitivity analyses to assess the impact of assumptions on your findings. Additionally, consulting with a statistician or data analyst experienced in handling violations of assumptions can be valuable in such situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
